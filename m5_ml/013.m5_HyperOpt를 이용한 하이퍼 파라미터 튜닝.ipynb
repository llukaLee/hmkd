{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3915ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 9.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\app\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\app\\lib\\site-packages (from hyperopt) (4.64.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\app\\lib\\site-packages (from hyperopt) (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\app\\lib\\site-packages (from hyperopt) (1.21.5)\n",
      "Requirement already satisfied: future in c:\\app\\lib\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: scipy in c:\\app\\lib\\site-packages (from hyperopt) (1.9.1)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\app\\lib\\site-packages (from hyperopt) (2.8.4)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "     ------------------------------------- 200.5/200.5 kB 12.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\app\\lib\\site-packages (from tqdm->hyperopt) (0.4.5)\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df85fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python.exe -m pip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78dade4",
   "metadata": {},
   "source": [
    "### HyperOpt 라이브러리의 주요 함수와 개념\n",
    "\n",
    "- fmin: 이 함수는 최적화 과정을 수행하는 주요 함수입니다. 이 함수는 목표 함수(fn), 검색 공간(space), 최적화 알고리즘(algo), 그리고 최대 평가 횟수(max_evals) 등을 인자로 받습니다. 이 함수는 최적의 하이퍼파라미터 설정을 찾기 위해 주어진 알고리즘을 사용하여 검색 공간을 탐색하고, 각 설정에 대해 목표 함수를 평가합니다.\n",
    "\n",
    "- tpe: 이것은 Tree-structured Parzen Estimator(TPE) 알고리즘을 나타내며, HyperOpt에서 사용할 수 있는 최적화 알고리즘 중 하나입니다. TPE는 베이지안 최적화 알고리즘의 한 종류로, 이전의 평가 결과를 기반으로 하여 다음에 테스트할 하이퍼파라미터를 선택합니다. 이렇게 하면 더 좋은 결과를 내는 하이퍼파라미터의 영역을 더 자주 탐색하게 됩니다.\n",
    "\n",
    "- hp: 이것은 HyperOpt의 검색 공간을 정의하는 데 사용되는 함수들을 담고 있는 모듈입니다. 예를 들어, hp.uniform('x', 0, 1)은 0과 1 사이에서 균일하게 분포한 실수 값을 가지는 'x'라는 하이퍼파라미터를 정의합니다. 다른 함수로는 hp.choice (여러 선택 사항 중 하나를 선택), hp.normal (정규 분포에서 값을 선택) 등이 있습니다.\n",
    "\n",
    "- STATUS_OK: 이것은 목표 함수가 성공적으로 완료되었음을 나타내는 상태 코드입니다. 목표 함수는 손실값과 상태 코드를 포함하는 딕셔너리를 반환해야 합니다. 이 상태 코드는 HyperOpt가 평가를 제대로 수행했는지 판단하는 데 사용됩니다. 만약 다른 값을 반환하면, HyperOpt는 해당 평가가 실패했다고 판단하고, 해당 설정을 더 이상 탐색하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91416982",
   "metadata": {},
   "source": [
    "### Tree-structured Parzen Estimator (TPE)\n",
    "- 하이퍼파라미터 최적화를 위한 알고리즘 중 하나입니다. Bayesian optimization의 한 종류로, 하이퍼파라미터의 새로운 조합을 선택하는 방법으로 주로 사용됩니다.\n",
    "\n",
    "- TPE 알고리즘의 핵심 아이디어는 과거의 평가 결과를 기반으로 하이퍼파라미터의 좋은 값과 나쁜 값에 대한 확률 모델을 구축하고, 이 모델을 사용하여 다음에 시도할 하이퍼파라미터 값을 선택하는 것입니다.\n",
    "\n",
    "- TPE는 이를 위해 두 개의 확률 분포 l(x)와 g(x)를 사용합니다. 여기서 x는 하이퍼파라미터를 의미하며, l(x)는 과거의 좋은 하이퍼파라미터 값들에 대한 분포를 나타내고, g(x)는 모든 과거의 하이퍼파라미터 값들에 대한 분포를 나타냅니다.\n",
    "\n",
    "- 이 두 분포를 이용해 새로운 하이퍼파라미터 값 x를 선택할 때, l(x)/g(x)가 큰 값, 즉 과거의 좋은 하이퍼파라미터 값들에 더 가까운 값을 선택합니다.\n",
    "\n",
    "- 이런 방식으로, TPE는 점점 더 좋은 하이퍼파라미터 값을 찾아가는 탐색 과정을 수행합니다. 이는 전통적인 Grid Search나 Random Search에 비해 효율적이며, 보다 적은 평가로 좋은 하이퍼파라미터 값을 찾을 수 있게 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14fba5d",
   "metadata": {},
   "source": [
    "### make_classification 함수 매개변수\n",
    "\n",
    "- n_samples: 생성할 샘플의 개수를 지정합니다. 기본값은 100입니다.\n",
    "- n_features: 독립 변수의 개수를 지정합니다. 기본값은 20입니다.\n",
    "- n_informative: 종속 변수와 관련된 독립 변수의 수를 지정합니다. 기본값은 2입니다.\n",
    "- n_redundant: 다른 독립 변수의 선형 조합으로 생성된 독립 변수의 수를 지정합니다. 기본값은 2입니다.\n",
    "- n_classes: 생성할 클래스(또는 레이블)의 개수를 지정합니다. 기본값은 2입니다.\n",
    "\n",
    "이 함수는 X와 y의 두 개의 배열을 반환합니다. X는 n_samples x n_features 크기의 2차원 배열로, 독립 변수를 포함하고 있습니다. y는 n_samples 크기의 1차원 배열로, 각 샘플의 클래스 레이블을 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a29c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000개의 샘플, 10개의 독립 변수, 그리고 2개의 클래스로 구성된 가상 데이터셋을 생성\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8120cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [00:01<00:00, 52.80trial/s, best loss: 0.09000000000000008]\n",
      "{'C': 0.019212137070514446}\n"
     ]
    }
   ],
   "source": [
    "# make_classification 함수는 sklearn.datasets 모듈의 일부로, 분류 문제에 사용할 수 있는 가상 데이터셋을 생성하는데 사용\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 데이터 생성\n",
    "X, y = make_classification()\n",
    "\n",
    "# HyperOpt에 의해 최적화될 목표 함수를 정의합니다.\n",
    "# 이 함수는 손실값을 반환하며, 손실값이 최소가 된느 하이퍼파라미터를 찾는 것이 목표입니다.\n",
    "def objective(args):\n",
    "    # 모델 설정\n",
    "    # C는 규제의 역수로, C값이 작을수록 규제가 강하며 C값이 클수록 규제가 약해집니다.\n",
    "    # Logistic Regression 모델을 초기화하고, HyperOpt가 최적화할 하이퍼파라미터 C를 설정합니다.\n",
    "    model = LogisticRegression(C=args[\"C\"])\n",
    "    \n",
    "    # 모델 검증\n",
    "    # 5-fold 교차 검증을 수행하고, 평균 정확돌르 계산\n",
    "    score = cross_val_score(model, X, y, cv=5).mean()\n",
    "    \n",
    "    # 손실값 계산 (분류 문제에서는 정확도를 사용하므로 1 - 정확도를 반환)\n",
    "    # 분류 문제에서는 정확도를 사용하므로, 손실값을 1 - 정확도로 계산\n",
    "    loss = 1 - score\n",
    "    # 손실값과 상태 코드를 반환합니다.\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "# 검색 공간 정의\n",
    "# 최적화할 하이퍼파라미터인 C의 범위를 정의합니다.\n",
    "space = {\n",
    "    'C': hp.loguniform('C', -5, 0),\n",
    "}\n",
    "\n",
    "# 최적화 실행\n",
    "# TPE 알고리즘을 사용하여 목표 함술르 최적화하고,\n",
    "# 최적의 하이퍼파라미터를 찾습니다. 최대 100회의 평가를 수행합니다.\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb68a0f",
   "metadata": {},
   "source": [
    "## HyperOpt 사용법\n",
    "- 입력 변수명과 입력값의 검색 공간 설정\n",
    "- 목적 함수의 설정\n",
    "- 목적 함수의 반환 최솟값을 가지는 최적 입력값을 유추"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a37a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# -10 ~ 10까지 1간격을 가지는 입력 변수 x와 -15 ~ 15까지 1간격으로 입력 변수 y설정.\n",
    "# hp.quniform(label, low, high, q) 함수는 low와 high 사이에서 일정 간격 q\n",
    "search_space = {'x': hp.quniform('x', -10, 10, 1), 'y':hp.quniform('y', -15, 15, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7f89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# 목적 함수를 생성. 변숫값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "# search_space는 하이퍼파라미터의 조합을 나타내는 딕셔너리 입니다. 이 딕셔너리는 'x'와 'y'라는\n",
    "# 두 개의 키를 가지고 있습니다. 이 두 키는 각각 목표 함수에서 사용될 두 개의 변수를 나타냅니다.\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y # retval이라는 변수에 목표 함수의 식을 계산한 결과를 저장\n",
    "    \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aedd7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 833.76trial/s, best loss: -224.0]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "# 입력 결과값을 저장한 Trials 객체값 생성.\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최소값을 반환하는 최적 입력 변수값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5,\n",
    "              trials=trial_val, rstate=np.random.default_rng(seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d14372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 833.07trial/s, best loss: -296.0]\n",
      "best: {'x': 2.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "# max_evals를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20,\n",
    "              trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:',best_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661ff766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': -64.0, 'status': 'ok'}, {'loss': -184.0, 'status': 'ok'}, {'loss': 56.0, 'status': 'ok'}, {'loss': -224.0, 'status': 'ok'}, {'loss': 61.0, 'status': 'ok'}, {'loss': -296.0, 'status': 'ok'}, {'loss': -40.0, 'status': 'ok'}, {'loss': 281.0, 'status': 'ok'}, {'loss': 64.0, 'status': 'ok'}, {'loss': 100.0, 'status': 'ok'}, {'loss': 60.0, 'status': 'ok'}, {'loss': -39.0, 'status': 'ok'}, {'loss': 1.0, 'status': 'ok'}, {'loss': -164.0, 'status': 'ok'}, {'loss': 21.0, 'status': 'ok'}, {'loss': -56.0, 'status': 'ok'}, {'loss': 284.0, 'status': 'ok'}, {'loss': 176.0, 'status': 'ok'}, {'loss': -171.0, 'status': 'ok'}, {'loss': 0.0, 'status': 'ok'}]\n"
     ]
    }
   ],
   "source": [
    "# fmin()에 인자로 들어가는 Trials 객체의 result 속성에 파이썬 리스트로 목적 함수 반환값들이 저장됨\n",
    "# 리스트 내부의 개별 원소는 {'loss': 함수 반환값, 'status': 반환 상태값}와 같은 딕셔너리임.\n",
    "print(trial_val.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a20cc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [-6.0, -4.0, 4.0, -4.0, 9.0, 2.0, 10.0, -9.0, -8.0, -0.0, -0.0, 1.0, 9.0, 6.0, 9.0, 2.0, -2.0, -4.0, 7.0, -0.0], 'y': [5.0, 10.0, -2.0, 12.0, 1.0, 15.0, 7.0, -10.0, 0.0, -5.0, -3.0, 2.0, 4.0, 10.0, 3.0, 3.0, -14.0, -8.0, 11.0, -0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Trials 객체의 vals 속성에 {'입력변수명':개별 수행 시마다 입력된 값 리스트}형태로 저장됨.\n",
    "print(trial_val.vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958d2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# results에서 loss 키값에 해당하는 밸류들을 추출하여 list로 생성.\n",
    "losses = [loss_dict]\n",
    "\n",
    "# DataFrame으로 생성\n",
    "result_df = pd.DataFrame({'x': trial_val.va})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed031c5",
   "metadata": {},
   "source": [
    "### HyperOpt를 이용한 XGBoost 하이퍼 파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1e3ab",
   "metadata": {},
   "source": [
    "#### 과제2_0523. 위스콘신 유방암 데이터 세트를 로딩해서 XGBooster 알고리즘으로 모델링 및 평가를 수행하세요. 단 HyperOpt를 이용해서 하이퍼파라미터를 최적화하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839012cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "cancer_df['target']=dataset.target\n",
    "X_features = cancer_df.iloc[:,:-1]\n",
    "y_label = cancer_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6a96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=156)\n",
    "\n",
    "# 앞에서 추출한 학습 데이터를 다시 학습과 검증 데이터로 분리\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e0a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 20까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2 사이 정규 분포된 값으로 검색.\n",
    "xgb_search_space = {'max_depth':hp.quniform('max_depth', 5, 20, 1),\n",
    "                   'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                   'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                   'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0210ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# fmin()에서 입력된 search_space 값으로 입력된 모든 값은 실수형임.\n",
    "# XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함.\n",
    "# 정확도는 높을수록 더 좋은 수치임. -1 * 정확도를 곱해서 큰 정확도 값일수록 최소가 되도록 변환\n",
    "def objective_func(search_space):\n",
    "    # 수행 시간 절약을 위해 nestimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                           min_child_weight=int(search_space['min_child_weight']),\n",
    "                           learning_rate=search_space['learning_rate'], # 개별 트리를 학습할 때만다 두\n",
    "                           eval_metric='logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "    \n",
    "    # accuracy는 cv=3 개수만큼 roc-auc 결과를 리스트로 가짐. 이를 평균해서 반환하되 -1을 곱함.\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4c11d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [00:13<00:00,  3.81trial/s, best loss: -0.9604827466016034]\n",
      "best: {'colsample_bytree': 0.7767383218403126, 'learning_rate': 0.08962397914323136, 'max_depth': 7.0, 'min_child_weight': 2.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "           space=xgb_search_space,\n",
    "           algo=tpe.suggest,\n",
    "           max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "           trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "print('best:',best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72dd8bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colsample_bytree:0.77674, learning_rate:0.08962, max_depth:7, min_child_weight:2\n"
     ]
    }
   ],
   "source": [
    "print('colsample_bytree:{0}, learning_rate:{1}, max_depth:{2}, min_child_weight:{3}'.format(\n",
    "    round(best['colsample_bytree'],5), round(best['learning_rate'],5),\n",
    "    int(best['max_depth']), int(best['min_child_weight'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a8b0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precistion = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1()\n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print추가\n",
    "    print('정확도 : {0:.4f}, 정밀도:{1:.4f}, 재현율: {2:.4f},\\\n",
    "          F1: {3:.4f}, AUC: {4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64329752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:29:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"min_chile_weight\" } are not used.\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.61682\tvalidation_1-logloss:0.63724\n",
      "[1]\tvalidation_0-logloss:0.55214\tvalidation_1-logloss:0.59030\n",
      "[2]\tvalidation_0-logloss:0.49727\tvalidation_1-logloss:0.55482\n",
      "[3]\tvalidation_0-logloss:0.45082\tvalidation_1-logloss:0.52620\n",
      "[4]\tvalidation_0-logloss:0.40833\tvalidation_1-logloss:0.50155\n",
      "[5]\tvalidation_0-logloss:0.37025\tvalidation_1-logloss:0.47081\n",
      "[6]\tvalidation_0-logloss:0.33803\tvalidation_1-logloss:0.44542\n",
      "[7]\tvalidation_0-logloss:0.30969\tvalidation_1-logloss:0.42250\n",
      "[8]\tvalidation_0-logloss:0.28387\tvalidation_1-logloss:0.41138\n",
      "[9]\tvalidation_0-logloss:0.26053\tvalidation_1-logloss:0.39277\n",
      "[10]\tvalidation_0-logloss:0.23890\tvalidation_1-logloss:0.37658\n",
      "[11]\tvalidation_0-logloss:0.22056\tvalidation_1-logloss:0.36342\n",
      "[12]\tvalidation_0-logloss:0.20319\tvalidation_1-logloss:0.35202\n",
      "[13]\tvalidation_0-logloss:0.18754\tvalidation_1-logloss:0.33996\n",
      "[14]\tvalidation_0-logloss:0.17397\tvalidation_1-logloss:0.32914\n",
      "[15]\tvalidation_0-logloss:0.16115\tvalidation_1-logloss:0.32096\n",
      "[16]\tvalidation_0-logloss:0.14910\tvalidation_1-logloss:0.31110\n",
      "[17]\tvalidation_0-logloss:0.13842\tvalidation_1-logloss:0.30454\n",
      "[18]\tvalidation_0-logloss:0.12898\tvalidation_1-logloss:0.29794\n",
      "[19]\tvalidation_0-logloss:0.12039\tvalidation_1-logloss:0.29046\n",
      "[20]\tvalidation_0-logloss:0.11236\tvalidation_1-logloss:0.28526\n",
      "[21]\tvalidation_0-logloss:0.10505\tvalidation_1-logloss:0.27902\n",
      "[22]\tvalidation_0-logloss:0.09848\tvalidation_1-logloss:0.27459\n",
      "[23]\tvalidation_0-logloss:0.09260\tvalidation_1-logloss:0.26999\n",
      "[24]\tvalidation_0-logloss:0.08725\tvalidation_1-logloss:0.26653\n",
      "[25]\tvalidation_0-logloss:0.08242\tvalidation_1-logloss:0.26468\n",
      "[26]\tvalidation_0-logloss:0.07765\tvalidation_1-logloss:0.26175\n",
      "[27]\tvalidation_0-logloss:0.07344\tvalidation_1-logloss:0.25977\n",
      "[28]\tvalidation_0-logloss:0.06975\tvalidation_1-logloss:0.25919\n",
      "[29]\tvalidation_0-logloss:0.06622\tvalidation_1-logloss:0.26030\n",
      "[30]\tvalidation_0-logloss:0.06270\tvalidation_1-logloss:0.25612\n",
      "[31]\tvalidation_0-logloss:0.05966\tvalidation_1-logloss:0.25502\n",
      "[32]\tvalidation_0-logloss:0.05683\tvalidation_1-logloss:0.25492\n",
      "[33]\tvalidation_0-logloss:0.05414\tvalidation_1-logloss:0.25221\n",
      "[34]\tvalidation_0-logloss:0.05180\tvalidation_1-logloss:0.25091\n",
      "[35]\tvalidation_0-logloss:0.04941\tvalidation_1-logloss:0.25115\n",
      "[36]\tvalidation_0-logloss:0.04738\tvalidation_1-logloss:0.25271\n",
      "[37]\tvalidation_0-logloss:0.04518\tvalidation_1-logloss:0.25194\n",
      "[38]\tvalidation_0-logloss:0.04341\tvalidation_1-logloss:0.25288\n",
      "[39]\tvalidation_0-logloss:0.04169\tvalidation_1-logloss:0.25257\n",
      "[40]\tvalidation_0-logloss:0.03981\tvalidation_1-logloss:0.25015\n",
      "[41]\tvalidation_0-logloss:0.03847\tvalidation_1-logloss:0.25180\n",
      "[42]\tvalidation_0-logloss:0.03686\tvalidation_1-logloss:0.25267\n",
      "[43]\tvalidation_0-logloss:0.03531\tvalidation_1-logloss:0.25186\n",
      "[44]\tvalidation_0-logloss:0.03358\tvalidation_1-logloss:0.24918\n",
      "[45]\tvalidation_0-logloss:0.03232\tvalidation_1-logloss:0.24795\n",
      "[46]\tvalidation_0-logloss:0.03129\tvalidation_1-logloss:0.25062\n",
      "[47]\tvalidation_0-logloss:0.03011\tvalidation_1-logloss:0.25131\n",
      "[48]\tvalidation_0-logloss:0.02909\tvalidation_1-logloss:0.25288\n",
      "[49]\tvalidation_0-logloss:0.02821\tvalidation_1-logloss:0.25293\n",
      "[50]\tvalidation_0-logloss:0.02728\tvalidation_1-logloss:0.25221\n",
      "[51]\tvalidation_0-logloss:0.02651\tvalidation_1-logloss:0.25265\n",
      "[52]\tvalidation_0-logloss:0.02572\tvalidation_1-logloss:0.25291\n",
      "[53]\tvalidation_0-logloss:0.02500\tvalidation_1-logloss:0.25586\n",
      "[54]\tvalidation_0-logloss:0.02398\tvalidation_1-logloss:0.25419\n",
      "[55]\tvalidation_0-logloss:0.02338\tvalidation_1-logloss:0.25216\n",
      "[56]\tvalidation_0-logloss:0.02260\tvalidation_1-logloss:0.24992\n",
      "[57]\tvalidation_0-logloss:0.02190\tvalidation_1-logloss:0.25037\n",
      "[58]\tvalidation_0-logloss:0.02127\tvalidation_1-logloss:0.25118\n",
      "[59]\tvalidation_0-logloss:0.02067\tvalidation_1-logloss:0.25251\n",
      "[60]\tvalidation_0-logloss:0.02012\tvalidation_1-logloss:0.25231\n",
      "[61]\tvalidation_0-logloss:0.01961\tvalidation_1-logloss:0.25168\n",
      "[62]\tvalidation_0-logloss:0.01916\tvalidation_1-logloss:0.25152\n",
      "[63]\tvalidation_0-logloss:0.01877\tvalidation_1-logloss:0.25235\n",
      "[64]\tvalidation_0-logloss:0.01831\tvalidation_1-logloss:0.25278\n",
      "[65]\tvalidation_0-logloss:0.01791\tvalidation_1-logloss:0.25262\n",
      "[66]\tvalidation_0-logloss:0.01751\tvalidation_1-logloss:0.25451\n",
      "[67]\tvalidation_0-logloss:0.01710\tvalidation_1-logloss:0.25604\n",
      "[68]\tvalidation_0-logloss:0.01674\tvalidation_1-logloss:0.25636\n",
      "[69]\tvalidation_0-logloss:0.01646\tvalidation_1-logloss:0.25704\n",
      "[70]\tvalidation_0-logloss:0.01615\tvalidation_1-logloss:0.25757\n",
      "[71]\tvalidation_0-logloss:0.01590\tvalidation_1-logloss:0.25862\n",
      "[72]\tvalidation_0-logloss:0.01556\tvalidation_1-logloss:0.25788\n",
      "[73]\tvalidation_0-logloss:0.01527\tvalidation_1-logloss:0.25953\n",
      "[74]\tvalidation_0-logloss:0.01499\tvalidation_1-logloss:0.25997\n",
      "[75]\tvalidation_0-logloss:0.01473\tvalidation_1-logloss:0.26037\n",
      "[76]\tvalidation_0-logloss:0.01446\tvalidation_1-logloss:0.26214\n",
      "[77]\tvalidation_0-logloss:0.01419\tvalidation_1-logloss:0.25941\n",
      "[78]\tvalidation_0-logloss:0.01395\tvalidation_1-logloss:0.26015\n",
      "[79]\tvalidation_0-logloss:0.01373\tvalidation_1-logloss:0.26063\n",
      "[80]\tvalidation_0-logloss:0.01349\tvalidation_1-logloss:0.26075\n",
      "[81]\tvalidation_0-logloss:0.01332\tvalidation_1-logloss:0.25992\n",
      "[82]\tvalidation_0-logloss:0.01310\tvalidation_1-logloss:0.26130\n",
      "[83]\tvalidation_0-logloss:0.01296\tvalidation_1-logloss:0.25999\n",
      "[84]\tvalidation_0-logloss:0.01282\tvalidation_1-logloss:0.25946\n",
      "[85]\tvalidation_0-logloss:0.01267\tvalidation_1-logloss:0.26060\n",
      "[86]\tvalidation_0-logloss:0.01247\tvalidation_1-logloss:0.25940\n",
      "[87]\tvalidation_0-logloss:0.01234\tvalidation_1-logloss:0.25815\n",
      "[88]\tvalidation_0-logloss:0.01221\tvalidation_1-logloss:0.25847\n",
      "[89]\tvalidation_0-logloss:0.01208\tvalidation_1-logloss:0.25993\n",
      "[90]\tvalidation_0-logloss:0.01195\tvalidation_1-logloss:0.26036\n",
      "[91]\tvalidation_0-logloss:0.01184\tvalidation_1-logloss:0.26195\n",
      "[92]\tvalidation_0-logloss:0.01172\tvalidation_1-logloss:0.26125\n",
      "[93]\tvalidation_0-logloss:0.01160\tvalidation_1-logloss:0.26155\n",
      "[94]\tvalidation_0-logloss:0.01150\tvalidation_1-logloss:0.26122\n",
      "[95]\tvalidation_0-logloss:0.01138\tvalidation_1-logloss:0.26164\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_clf_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9744\\3671826847.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mpred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_wrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mget_clf_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_clf_eval' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators=400,\n",
    "                           learning_rate=round(best['learning_rate'],5),\n",
    "                           max_depth=int(best['max_depth']),\n",
    "                           min_chile_weight=int(best['min_child_weight']),\n",
    "                           colsample_bytree=round(best['colsample_bytree'],5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='logloss',\n",
    "               eval_set=evals, verbose=True)\n",
    "\n",
    "preds = xgb_wrapper.predict(X_test)\n",
    "pred_proba = xgb_wrapper.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
